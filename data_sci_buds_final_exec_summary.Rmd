---
title: "Stat 301-3 Final Executive Summary"
author: "Data Sci Buds (Pranav, Lily, Minjee, Tammy)"
date: '2022-06-07'
output:
  html_document:
    toc: true
    toc_float: true
    highlight: "tango"
    code_folding: "hide"
editor_options: 
  chunk_output_type: console
---

## Data and Research Question

Our dataset includes purchase information, such as product name, quantity sold, and profit, for different products sold in a large superstore. This superstore sells a variety of products, including furniture and office supplies to customers across the US. Our research question is: How can we best predict profit given information about a particular transaction? We believe that the variables category, sales, quantity, and discount will be the most useful predictors. 

<br>

**Citation:** https://www.kaggle.com/datasets/vivek468/superstore-dataset-final

```{r, message = F, warning = F, echo = F}
#load packages 
library(tidyverse)
library(tidymodels)
library(janitor)
library(naniar)
library(ggplot2)

# load data
superstore_dat <- read_csv(file = "data/unprocessed/Superstore_data.csv") %>% 
  clean_names() %>% 
  mutate(
    ship_mode = factor(ship_mode),
    segment = factor(segment),
    city = factor(city),
    state = factor(state),
    region = factor(region),
    category = factor(category),
    sub_category = factor(sub_category)
  )
```

```{r, echo = F}
# load rda files
load(file = "model_info/model_setup.rda")
load(file = "results/tuned_models.rda")
```

## EDA

According to the univariate profit graph below, profit peaks at around $10-15 per product transaction.

```{r, message = F, warning = F, echo = F}
# univariate profit graph
ggplot(superstore_dat, aes(profit)) +
  geom_density() +
  xlim(c(-100, 150)) +
  ggtitle("Profit or Loss Incurred from Sales")
```

The bivariate sub-category graph shows that the copier subcategory brings substantially more profit than other subcategories, with an average of 800. We can conclude that the subcategory of profit will be important when predicting profit, especially because of the huge profits brought by copiers. 

```{r, message = F, warning = F, echo = F}
# bivariate sub-category graph
superstore_dat %>%
  group_by(sub_category) %>%
  mutate(avg_prf = mean(profit)) %>%
  ggplot(aes(sub_category, avg_prf)) +
  geom_bar(stat="identity", position=position_dodge()) +
  labs(
    title = "Average Profit for Different Sub-Categories",
    x = "Subcategory",
    y = "Average Profit"
  ) +
  theme(axis.text.x = element_text(angle = 90))
```


## Model Fitting
### Elastic Net
The best elastic net model has a penalty of 1 and a mixture of 0.05, which yielded an rmse of 181. 
```{r, echo = F}
show_best(enet_tuned, metric = "rmse") %>% head(1)
```


### K Nearest Neighbor
The best k nearest neighbors model had 8 neighbors, which yielded an rmse of 170.
```{r, echo = F}
show_best(knn_tuned, metric = "rmse") %>% head(1)
```


### Random Forest
The best random forest model has an mtry of 20 and a min_n of 2, yielding an rmse of 110.
```{r, echo = F}
show_best(rf_tuned, metric = "rmse") %>% head(1)
```

### Boosted Tree
The best boosted tree model has an mtry of 20, min_n of 2, and a learn rate of 0.631. The rmse is 112.
```{r, echo = F}
show_best(boost_tuned, metric = "rmse") %>% head(1)
```

### Support Vector Machine Polynomial
The best support vector machine polynomial model has a cost of 32, degree of 2, an a scale factor of 0.1, which yielded an rmse of 94.9.
```{r, echo = F}
show_best(svm_p_tuned, metric = "rmse") %>% head(1)
```

### Support Vector Machine Radial Base Function
The best support vector machine radial basis function model has a cost of 32 and an rbf_sigma of 0.00001, which yielded an rmse of 190, meaning that it is one of our worse models because of its high rmse. 
```{r, echo = F}
show_best(svm_r_tuned, metric = "rmse") %>% head(1)
```

### Single Layer Neural Network
The best single layer neural network model has 10 hidden_units and a penalty of 1, which yielded an rmse of 178.
```{r, echo = F}
show_best(nnet_tuned, metric = "rmse") %>% head(1)
```

### MARS
The best MARS model has 5 num_terms and a prod_degree of 2, yielding an rmse of 155. 
```{r, echo = F}
show_best(mars_tuned, metric = "rmse") %>% head(1)
```

## Best Model Fitting
From the 8 models, we see the best model is the support vector machine polynomial model with the lowest rmse of 94.9. The second best model is the random forest model, which has an rmse of 110, while the worst model was the support vector machine radial basis function with an rmse of 190. 
<br>
We fit the support vector machine polynomial model to the testing set and predicted with the test set, which ended up yielding a higher rmse of 167â€”still better than most of the models' rmses from the training folds so far. This phenomenon of the rmse being higher when fit to the testing data is likely because the training data is assessed on data that has been learnt before, while the test dataset may have data that is unknown/not common that may give more errors or misclassification when doing prediction. 

```{r, echo = F}
load("results/best_model_fit_metric.rda")

svm_p_rmse_test
```

## Debrief and Next Steps
We tested a variety of 8 models: elastic net, k nearest neighbors, boosted tree, random forest, support vector machine polynomial, support vector machine radial, single layer neural network, and MARS. The best model with the lowest rmse was the support vector machine polynomial model. If we wanted to create a better model, we could have tried using different recipes by creating interactions, including more step functions, or removing more predictors. We also could have tried different tuning parameters (and ranges), specifically for boosted tree and random forest. 

## GitHub Repo Link

<br>

https://github.com/STAT301III/final-project-data-sci-buds.git











